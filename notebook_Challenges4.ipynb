{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b12c8dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
        "체인을 수동으로 구현해야 합니다.\n",
        "체인에 ConversationBufferMemory를 부여합니다.\n",
        "이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
        "체인에 다음 질문을 합니다:\n",
        "Aaronson 은 유죄인가요?\n",
        "그가 테이블에 어떤 메시지를 썼나요?\n",
        "Julia 는 누구인가요?\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "# 1. 문서 로드 (Document Loading)\n",
        "loader = TextLoader(\"./files/1984_gist.txt\", encoding='utf-8')\n",
        "\n",
        "cache_dir = LocalFileStore(\"./.cache/\")\n",
        "\n",
        "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=100,\n",
        ")\n",
        "\n",
        "loader = TextLoader(\"./files/1984_gist.txt\", encoding='utf-8')\n",
        "\n",
        "docs = loader.load_and_split(text_splitter=splitter)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
        "    embeddings, cache_dir\n",
        ")\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(document.page_content for document in docs)\n",
        "\n",
        "def load_memory(_):\n",
        "    return memory.load_memory_variables({})[\"history\"]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{question}\"),\n",
        "])\n",
        "\n",
        "chain = RunnablePassthrough.assign(\n",
        "    context=lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
        "    history=load_memory\n",
        ") | prompt | llm\n",
        "\n",
        "def invoke_chain(question):\n",
        "    result = chain.invoke({\"question\": question})\n",
        "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Answer: {result.content}\\n\")\n",
        "\n",
        "invoke_chain(\"Aaronson 은 유죄인가요?\")\n",
        "invoke_chain(\"그가 테이블에 어떤 메시지를 썼나요?\")\n",
        "invoke_chain(\"Julia 는 누구인가요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "rag_cell",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Victory Mansions is a dilapidated and run-down apartment building in a dystopian society, as depicted in George Orwell\\'s novel \"1984.\" It is characterized by poor living conditions, lack of amenities, and an oppressive atmosphere. The building symbolizes decay and deprivation in the society portrayed in the novel. The protagonist, Winston Smith, resides in Victory Mansions, where he has his own corner table always reserved for him due to others avoiding sitting too close to him. Despite its shabby appearance and foul smell, Winston finds a sense of routine and familiarity in this place, with the chessboard always waiting for him and the staff knowing his habits without being told.')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
        "체인을 수동으로 구현해야 합니다.\n",
        "체인에 ConversationBufferMemory를 부여합니다.\n",
        "이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
        "체인에 다음 질문을 합니다:\n",
        "Aaronson 은 유죄인가요?\n",
        "그가 테이블에 어떤 메시지를 썼나요?\n",
        "Julia 는 누구인가요?\n",
        "\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "# 1. 문서 로드 (Document Loading)\n",
        "loader = TextLoader(\"./files/1984_gist.txt\", encoding='utf-8')\n",
        "\n",
        "\n",
        "# 2. 문서 쪼개기 (Document Splitting, CharacterTextSplitter)\n",
        "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=100,\n",
        ")\n",
        "docs = loader.load_and_split(text_splitter=splitter)\n",
        "\n",
        "# 3. 임베딩 생성 및 캐시 (OpenAIEmbeddings, CacheBackedEmbeddings)\n",
        "cache_dir = LocalFileStore(\"./.cache/\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
        "    embeddings, cache_dir\n",
        ")\n",
        "\n",
        "# 4. 벡터 스토어 생성 (FAISS)\n",
        "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 5. 대화 메모리와 질문 처리 (ConversationBufferMemory)\n",
        "memory = ConversationBufferMemory(\n",
        "    llm=llm,\n",
        "    max_token_limit=120,\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(document.page_content for document in docs)\n",
        "\n",
        "def load_memory(_):\n",
        "    return memory.load_memory_variables({})[\"chat_history\"]\n",
        "\n",
        "# 6. 체인 연결 \n",
        "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"\n",
        "            Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim. If there is no relevant text, return : ''\n",
        "            -------\n",
        "            {context}\n",
        "            \"\"\",\n",
        "        ),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "map_doc_chain = map_doc_prompt | llm\n",
        "\n",
        "def map_docs(inputs):\n",
        "    documents = inputs[\"documents\"]\n",
        "    question = inputs[\"question\"]\n",
        "    return \"\\n\\n\".join(\n",
        "        map_doc_chain.invoke(\n",
        "            {\"context\": doc.page_content, \"question\": question}\n",
        "        ).content\n",
        "        for doc in documents\n",
        "    )\n",
        "\n",
        "map_chain = {\n",
        "    \"documents\": retriever,\n",
        "    \"question\": RunnablePassthrough(),\n",
        "} | RunnableLambda(map_docs)\n",
        "\n",
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"\n",
        "            Given the following extracted parts of a long document and a question, create a final answer. \n",
        "            If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
        "            ------\n",
        "            {context}\n",
        "            \"\"\",\n",
        "        ),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = {\"context\":map_chain, \"question\" : RunnablePassthrough(), \"extra\": RunnablePassthrough()} | final_prompt | llm\n",
        "\n",
        "chain.invoke(\"Describe Victory Mansions\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
